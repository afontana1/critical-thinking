# Course 10 – Scientific Reasoning

**Subtitle:** How Science Uses Evidence, Models, and Institutions to Learn About the World

---

## Course Overview: Scientific Reasoning – From Hypotheses to Institutions

**Big question:**
How does science actually turn messy observations into relatively stable knowledge – through *reasoning*, *methods*, *models*, and *institutions* – and how can we critically engage with that whole ecosystem?

**By the end, students should be able to:**

* Distinguish **scientific reasoning** from everyday reasoning, and from pseudoscience and “science-y” rhetoric. ([Stanford Encyclopedia of Philosophy][1])
* Explain the roles of **deduction, induction, abduction, and mechanistic reasoning** in scientific discovery and explanation. ([Wikipedia][2])
* Articulate how **theories, models, and data** relate: theory-ladenness of observation, theory virtues, underdetermination, and the evidential relationship between models and the world. ([Stanford Encyclopedia of Philosophy][3])
* Describe the **scientific process** across fields (natural, social, and formal sciences): question → design → data → analysis → explanation → publication → critique → revision. ([Stanford Encyclopedia of Philosophy][4])
* Use concepts from prior courses (data literacy, causality, bias, systems, models) to **analyze a research paper** as an argument: design, assumptions, causal structure, statistical inference, and uncertainty.
* Evaluate **theoretical claims** using “theoretical virtues” (simplicity, coherence, explanatory power, unification, fertility, etc.) and distinguish good theory revision from ad hoc rescue moves. ([Cambridge University Press & Assessment][5])
* Understand **scientific explanation** (unification, laws, mechanisms) and its limits in complex systems. ([Stanford Encyclopedia of Philosophy][6])
* Explain key ideas in **research methodology**: empirical research, experimental design, measurement and validity, statistical validity, sensitivity analysis, and computational modeling. ([Wikipedia][7])
* Describe the **reproducibility and replication crises**, and what counts as rigorous, reproducible research in practice (including measurement, metrology, and preregistration). ([Wikipedia][8])
* Critically assess the **institutional ecosystem of science**: peer review, academic publishing, metascience, publication/reporting bias, evidence-based practice, and systematic review. ([Wikipedia][9])

This course is a **capstone**: it assumes students have completed your courses on data literacy, causality, heuristics/bias, analytical thinking, systems thinking, and model thinking. Here we synthesize those tools in the specific context of **how science works**.

---

## Unit 1 – What Is Scientific Reasoning? Science, Non-Science, and Pseudoscience

### Guiding questions

* What makes a practice *scientific* – and why is that a messy question?
* How is scientific reasoning related to, but not identical with, “the scientific method” diagrams?
* Where do pseudoscience and “fake science” claims fit?

### Sub-units

1. **Science, Scientific Reasoning, and Branches of Science**

   * Science as *organized inquiry* aimed at reliable knowledge.
   * Distinguish **formal sciences** (math, logic), **natural sciences**, and **social/behavioral sciences**; how their methods partially overlap. ([Wikipedia][10])
   * “Scientific reasoning” as **structured argument from evidence** (drawing on Abelson, Ioannidis, Stigler from earlier courses).

2. **Scientific Method(s) vs “The Scientific Method”**

   * Use the **Outline of the Scientific Method** to show the classic cycle (observation → hypothesis → prediction → test → revision). ([Stanford Encyclopedia of Philosophy][4])
   * Contrast with historical and philosophical views from the SEP entry on scientific method: no single algorithm, multiple methods across fields. ([Stanford Encyclopedia of Philosophy][4])
   * Place earlier course content (study design, causality, models) *inside* this broader picture.

3. **Theory, Observation, and Objectivity**

   * **Theory-ladenness of observation**: what we “see” depends on conceptual schemes and instruments. ([Stanford Encyclopedia of Philosophy][3])
   * **Scientific objectivity** as a *cluster* of practices (replication, transparency, plurality, robustness), not a mystical property. ([Stanford Encyclopedia of Philosophy][11])

4. **Pseudoscience and the Demarcation Problem**

   * SEP on **pseudoscience**: features such as immunizing strategies, lack of testable predictions, selective use of evidence. ([Stanford Encyclopedia of Philosophy][1])
   * Connect to your **Causality** and **Bias** courses: confirmation bias, motivated reasoning, and illusory correlation as engines of pseudoscience.
   * Use familiar examples (astrology, homeopathy, some “brain training” products) as demarcation case studies.

### Core readings

* Stanford Encyclopedia of Philosophy entries on **Scientific Method**, **Scientific Objectivity**, **Theory and Observation in Science**, and **Pseudoscience**. ([Stanford Encyclopedia of Philosophy][4])
* Karl Pearson, *The Grammar of Science* (for early views on science, statistics, and law-like description). ([Wikipedia][12])
* Henri Poincaré, *Science and Hypothesis* (convention, geometry, and the structure of scientific theories). ([Project Gutenberg][13])

---

## Unit 2 – Forms of Inference in Science: Deduction, Induction, Abduction, Mechanisms

### Guiding questions

* How do scientists actually move from data to hypotheses and from hypotheses to explanations?
* What is **abductive reasoning**, and why is it central to discovery?
* How do mechanistic stories fit alongside statistical and causal ones?

### Sub-units

1. **Three Core Inference Types**

   * **Deduction**: from general premises to specific conclusions.
   * **Induction**: from specific cases to general regularities.
   * **Abduction**: inference to the best explanation – from effect to plausible cause. ([Wikipedia][2])
   * Relate to your earlier **Causality** course (Mill’s methods, counterfactuals) and **Analytical Thinking** (argument structure).

2. **Abduction in Discovery and Explanation**

   * Magnani on **abduction** as a process of discovery across science and AI; cognitive and computational perspectives. ([SpringerLink][14])
   * Walton’s *Abductive Reasoning*: dialogue models of explanation; abduction in medicine, law, and everyday argument. ([PhilPapers][15])
   * Link to **hypothesis generation** in research methods and to “two plausible stories” boxes from your Causality course.

3. **Theory and Evidence in Development**

   * Barbara Koslowski: children’s developing sense of **theory–evidence coordination**; people aren’t just “Humean inductors,” they reason with causal theories. ([MIT Press Direct][16])
   * Connect to **heuristics and cognitive bias**: when intuitive theory–evidence coordination works and when it misfires.

4. **Mechanistic and Causal Reasoning**

   * Mechanistic explanations as “how” stories (entities + activities organized to produce a phenomenon).
   * Bullock & Green’s **“Yes, but what’s the mechanism?”**: why mechanism talk matters (and sometimes doesn’t) for interpreting experiments and interventions. ([UBC Psychology][17])
   * Tie back to your **Mechanisms, Cases, and Explanations** unit in the Causality course.

### Core readings

* Lorenzo Magnani, *Abduction, Reason, and Science: Processes of Discovery and Explanation*. ([SpringerLink][14])
* Douglas Walton, *Abductive Reasoning*. ([PhilPapers][15])
* Barbara Koslowski, *Theory and Evidence: The Development of Scientific Reasoning*. ([MIT Press Direct][16])
* John G. Bullock & Donald P. Green, “Yes, but What’s the Mechanism?” (on the role of mechanisms in causal inference). ([UBC Psychology][17])

---

## Unit 3 – Theories, Models, and Theoretical Virtues

### Guiding questions

* What is a **scientific theory**, and how is it related to models and laws?
* How do scientists *evaluate* competing theories when data underdetermine them?
* What are **theoretical virtues**, and how do they guide theory choice?

### Sub-units

1. **Theories, Laws, and Models**

   * Theories as **structured networks of claims**; models as **specific representations** (mathematical, statistical, computational). ([Wikipedia][18])
   * Theory–observation interdependence: how instruments, operational definitions, and modeling assumptions shape data (bridging to your Data Literacy and Model Thinking courses).

2. **Theoretical Virtues**

   * Schindler’s *Theoretical Virtues in Science*: empirical adequacy, **simplicity**, internal and external consistency, explanatory power, unification, and fertility. ([Cambridge University Press & Assessment][5])
   * How these virtues are **normative but fallible** guides; trade-offs (simple vs realistic, unified vs domain-specific).

3. **Ad Hoc Hypotheses and Theory Evaluation**

   * **Ad hoc hypotheses**: when adding parameters or clauses only to save a theory from disconfirmation crosses the line. ([Stanford Encyclopedia of Philosophy][4])
   * Connect to **overfitting**, p-hacking, and “garden-of-forking-paths” from your Data Literacy and Bias courses.
   * “Theory evaluation” as weighing data, theoretical virtues, and research program health.

4. **Historical Perspectives on Theory**

   * Poincaré: conventionalism and the role of simplicity and convenience in theorem selection. ([Project Gutenberg][13])
   * Pearson: statistical and law-like conceptions of theory in *The Grammar of Science*. ([Wikipedia][12])

### Core readings

* Samuel Schindler, *Theoretical Virtues in Science*. ([Cambridge University Press & Assessment][5])
* Henri Poincaré, *Science and Hypothesis*. ([Project Gutenberg][13])
* Karl Pearson, *The Grammar of Science*. ([Wikipedia][12])
* SEP sections on **Models in Science** / **Scientific Explanation** as background. ([Wikipedia][18])

---

## Unit 4 – Scientific Process and Research Designs Across Fields

### Guiding questions

* How do **research methods** operationalize scientific reasoning in different sciences?
* How does this relate to what students already saw in Data Literacy and Causality?
* What are the distinctive challenges of **social science** vs natural science?

### Sub-units

1. **The Scientific Process Revisited**

   * Use the **Outline of the Scientific Method** as a scaffold; cue prior knowledge of study design, sampling, and inference. ([Stanford Encyclopedia of Philosophy][4])
   * Map where **analytical thinking**, **systems thinking**, **model thinking**, and **causal inference** plug in.

2. **Research Methods and Empirical Research**

   * Overview of **research methods** categories (experiments, surveys, field studies, archival/administrative data, qualitative methods). ([Wikipedia][7])
   * **Empirical research**: systematic observation/measurement to test or generate theory. ([Wikipedia][7])
   * Design trade-offs: internal vs external validity, realism vs control.

3. **Design of Experiments & Quasi-Experiments**

   * Core ideas: randomization, blocking, factorial designs, power and precision – conceptually, not mathematically. ([Wikipedia][19])
   * Connect back to **Causality** (experiments vs natural experiments) and **Data Literacy** (CONSORT, STROBE).

4. **Social Science as Science**

   * Bhattacherjee’s *Social Science Research: Principles, Methods, and Practices* as a bridge: operationalization, measurement, sampling, mixed methods. ([Digital Commons USF][20])
   * How social science uses **multiple methods** (surveys, experiments, case studies, secondary data) to triangulate.

5. **Scientific Modelling and Computational Fields**

   * Scientific modelling: conceptual, mathematical, and computational representations of phenomena. ([Wikipedia][21])
   * Rise of **computational fields of study** (computational biology, computational social science, climate models) and how they extend experimental and observational methods.

### Core readings

* Anol Bhattacherjee, *Social Science Research: Principles, Methods, and Practices* (open textbook). ([Digital Commons USF][20])
* Wikipedia overviews on **Research Methods**, **Empirical Research**, **Design of Experiments**, and **Scientific Modelling** (as navigational scaffolding). ([Wikipedia][7])
* Selections from your existing Data Literacy + Causality readings (CONSORT, STROBE, Hernán & Robins, Angrist & Pischke) referenced rather than re-explained.

---

## Unit 5 – Explanation, Mechanisms, and Understanding

### Guiding questions

* What counts as a **scientific explanation**?
* How do explanations differ across physics, biology, and social science?
* What is the role of **mechanisms** vs statistical regularities?

### Sub-units

1. **Classical Accounts of Explanation**

   * Very light treatment of Hempel’s **Deductive–Nomological** model and later unification accounts. ([Stanford Encyclopedia of Philosophy][6])
   * Strengths and limits in real scientific practice (probabilistic laws, mechanisms, narratives).

2. **Mechanistic Explanation**

   * Mechanisms as organized entities and activities producing a phenomenon; widely used in neuroscience, biology, and social science.
   * Reuse Bullock & Green’s mechanism paper: how mechanistic reasoning can discipline overinterpretation of experiments and support external validity judgments. ([UBC Psychology][17])

3. **Abduction, Mechanisms, and Models**

   * How abductive reasoning plus mechanistic thinking drives **hypothesis generation** and **model building** (tying back to Magnani, Walton, and your Model Thinking course).

4. **Different Kinds of Why-Questions**

   * “Why did this happen?” vs “How does this work?” vs “What would happen if…?”
   * Show how different explanations answer different why-questions; connect to **causal diagrams** and **systems archetypes**.

### Core readings

* SEP entry on **Scientific Explanation**. ([Stanford Encyclopedia of Philosophy][6])
* John G. Bullock & Donald P. Green, “Yes, but What’s the Mechanism?” ([UBC Psychology][17])
* Excerpts from Magnani & Walton showing abduction → explanation links. ([SpringerLink][14])

---

## Unit 6 – Measurement, Validity, and Statistical Reasoning in Science

*(This unit ties your Measurement/Data Literacy content explicitly to “scientific reasoning” and introduces a bit more on validity and metrology.)*

### Guiding questions

* What does it mean for a scientific measure, test, or inference to be **valid**?
* How do scientists reason from experiments and statistical results to claims about the world?

### Sub-units

1. **Measurement and Construct Validity**

   * Recap: reliability vs validity; psychometrics vs physical metrology (drawing implicitly on *Measurement Across the Sciences*).
   * *Constructing Validity: New Developments in Creating Objective Measuring Instruments* as an example of evolving validity theory (likely focusing on modern psychometrics / construct validity debates). ([PubMed][22])

2. **Statistical Validity in Science**

   * Types of validity: internal, external, construct, and **statistical conclusion validity**. ([Wikipedia][18])
   * Link to false positives/negatives, power, and misinterpretation of p-values and intervals (from your Data Literacy course).

3. **Sensitivity Analysis as Scientific Reasoning**

   * Not just a modeling trick: **sensitivity analysis** as a way to ask “which assumptions matter?” across experimental and modeling contexts. ([Wikipedia][19])
   * Connect back to your Model Thinking unit on uncertainty and robustness.

4. **Theory and Evidence Revisited**

   * Use Koslowski again: how people (including scientists) learn to coordinate theory and evidence in a disciplined way, rather than treating data as “brute facts.” ([MIT Press Direct][16])

### Core readings

* Selected chapters or papers from *Constructing Validity: New Developments in Creating Objective Measuring Instruments*. ([PubMed][22])
* Naomi Oreskes et al., “Verification, Validation, and Confirmation of Numerical Models in the Earth Sciences” (already used in Model Thinking but reframed as *scientific reasoning about models*). ([Wikipedia][18])
* SEP sections on **Validity** and **Models of Data** for deeper dives if desired. ([Wikipedia][18])

---

## Unit 7 – Reproducibility, Replication, and Rigorous Science

### Guiding questions

* What does it mean for a result to be **reproducible** or **replicable**?
* What has the **replication crisis** taught us about scientific reasoning and institutions?
* How do metrology and practice-based guidelines help?

### Sub-units

1. **Conceptual Landscape: Reproducibility, Replicability, Robustness**

   * Definitions: reproducibility (same data/code), replicability (new data), robustness (finding holds under varied assumptions).
   * Wikipedia overview on **reproducibility** and **replication crisis** as an accessible starting point. ([Wikipedia][8])

2. **Metrology Perspective on Reproducibility**

   * Anne Plant’s “Reproducibility in Science: A Metrology Perspective” – measurement uncertainty, calibration, and reference materials as foundations of reproducible science. ([Amazon][23])

3. **Rigorous Science in Practice**

   * Arturo Casadevall’s “Rigorous Science: A How-To” – practical norms: blinding, randomization, sample-size justification, transparent reporting, lab culture. ([ASM Journals][24])

4. **Replication as a Research Activity**

   * Brandt et al., “The Replication Recipe: What Makes for a Convincing Replication?” – criteria for high-quality replications (sampling, fidelity, statistical power, transparency). ([ScienceDirect][25])

5. **Your Prior Courses, Revisited**

   * Tie to your **Data Literacy Unit 6** (reporting & evidence synthesis) and **Heuristics/Bias** (overconfidence, p-hacking, motivated reasoning).
   * Scientific reasoning as not just *individual logic* but *institutional design* to counter error.

### Core readings

* Anne L. Plant, “Reproducibility in Science: A Metrology Perspective.” ([Amazon][23])
* Arturo Casadevall, “Rigorous Science: A How-To.” ([ASM Journals][24])
* Mark J. Brandt et al., “The Replication Recipe: What makes for a convincing replication?” ([ScienceDirect][25])
* Wikipedia / SEP overviews of **Reproducibility** and **Replication Crisis**. ([Wikipedia][8])

---

## Unit 8 – Science as a Social Institution: Publishing, Peer Review, Metascience

### Guiding questions

* How do **peer review, journals, and academic incentives** shape what counts as “scientific knowledge”?
* What is **metascience**, and how does it study scientific reasoning itself?
* How do **publication bias** and **reporting bias** distort the scientific record?

### Sub-units

1. **Academic Publishing and Peer Review**

   * Overview of **academic publishing** workflow: submission → peer review → revision → publication. ([Wikipedia][26])
   * Peer review’s strengths, failures, and reforms (open review, registered reports). ([Wikipedia][18])

2. **Publication and Reporting Biases**

   * **Publication bias**: tendency to publish positive/novel results. ([Wikipedia][9])
   * **Reporting bias**: selective reporting of outcomes, analyses, or subgroups. ([Wikipedia][9])
   * Connect to your Data Literacy course (CONSORT, PRISMA, GRADE).

3. **Metascience and Evidence-Based Practices**

   * Wikipedia overview of **metascience**: studying science using scientific methods (meta-research). ([Wikipedia][9])
   * Evidence-based practice & systematic reviews as **institutionalized scientific reasoning**: aggregating results, assessing quality, and making recommendations. ([Wikipedia][18])

4. **Systematic Review, Synthesis, and Credibility**

   * **Systematic reviews** and **meta-analyses**: structured methods to aggregate evidence. ([Wikipedia][9])
   * Source credibility and trust: who do we trust, and why? ([Wikipedia][9])

5. **Criticism of Academia**

   * Structural issues: publish-or-perish, perverse incentives, prestige bias, lack of diversity.
   * Use selections from **criticism of academia** and **scholarly communication** debates to frame how institutional reform is part of improving scientific reasoning. ([Wikipedia][9])

### Core readings

* Wikipedia overviews on **Peer Review**, **Academic Publishing**, **Publication Bias**, **Reporting Bias**, **Metascience**, **Systematic Review**, and **Evidence-Based Practice**. ([Wikipedia][9])
* Selected metascience/EBM readings already used in your Data Literacy course (Ioannidis, CONSORT, PRISMA, GRADE).

---

## Unit 9 – Pseudoscience, Methodology, and the Edges of Science

*(If you want, this can be folded into Units 1 and 8; I’m separating it to give demarcation and methodology a focused space.)*

### Guiding questions

* How do **methodology** debates shape what counts as “good science”?
* How can we systematically distinguish **scientific research** from pseudoscience or weak science?
* How do different fields (e.g., social sciences) defend their scientific status?

### Sub-units

1. **Methodology as Second-Order Reflection**

   * “Methodology” as the study of *how* we ought to design, conduct, and interpret research. ([Wikipedia][7])
   * Differences between **methods** (tools) and **methodology** (justifications, trade-offs).

2. **Demarcation Revisited**

   * SEP’s **Pseudoscience** + **Scientific Method** entries used to revisit demarcation in light of all the previous units. ([Stanford Encyclopedia of Philosophy][4])
   * Case exercises: classify borderline practices (certain alternative medicines, learning styles research, “grit” research, etc.) using your earlier causal & bias tools.

3. **Theoretical Virtues, Evidence, and “Science-ish” Rhetoric**

   * How appeals to **simplicity**, “mechanisms,” and statistics can be misused rhetorically.
   * Students practice spotting when theoretical virtues are being **invoked without substance**.

4. **Abduction and Hypothesis Space Management**

   * Using Magnani and Walton to show that scientific creativity is constrained by **background knowledge, theory virtues, and empirical discipline**, not just arbitrary guessing. ([SpringerLink][14])

### Core readings

* SEP entries on **Pseudoscience** and **Scientific Method**. ([Stanford Encyclopedia of Philosophy][1])
* Lorenzo Magnani, *Abduction, Reason, and Science* (selected chapters). ([SpringerLink][14])
* Douglas Walton, *Abductive Reasoning* (chapters on explanation and evaluation). ([PhilPapers][15])

---

## Unit 10 – Integrating Scientific Reasoning (Capstone)

### Guiding questions

* How do all the pieces – evidence, causality, models, bias, systems, institutions – integrate into a **scientific reasoning toolkit**?
* How can non-scientists read, use, and critique scientific claims responsibly?

### Components

1. **Scientific Reasoning Checklist**

When you encounter a scientific claim or paper, ask:

1. **Question & framing** – What is the precise question? How is it framed (causal, descriptive, mechanistic)?

2. **Design & methods** – What study design or modeling approach is used? How does it support causal/ explanatory claims (drawing on your Causality and Data Literacy courses)?

3. **Evidence & analysis** – What data, measurements, and analyses support the claims? How are uncertainty and statistical validity handled?

4. **Reasoning type** – Where are deduction, induction, abduction, and mechanistic reasoning at work?

5. **Theory & models** – What theory or model structure underlies the work? What theoretical virtues are invoked?

6. **Robustness & reproducibility** – Is there sensitivity analysis, preregistration, replication, or robustness checks? How would results change if key assumptions wiggled? ([Wikipedia][19])

7. **Institutions & incentives** – What journal, review process, and funding context is involved? Are there publication/reporting biases or conflicts of interest? ([Wikipedia][9])

8. **Use & ethics** – How will this evidence be used (policy, medicine, tech)? Who gains, who loses, who decides?

9. **Capstone Project Ideas**

You can mirror the structure from your Data Literacy and Model Thinking capstones:

* **Paper Autopsy**

  * Each group chooses a published empirical or modeling paper (ideally in their domain of interest).
  * Tasks:

    * Map the **scientific process** used: question → design → data → analysis → explanation → publication.
    * Draw a simple **causal DAG** and/or **systems diagram** representing the reasoning structure.
    * Identify the primary forms of inference (deductive, inductive, abductive, mechanistic).
    * Evaluate **theoretical virtues**, measurement validity, and statistical validity.
    * Assess **reproducibility/replication** prospects and institutional incentives (journal, field norms).
    * Write a short “scientific reasoning” memo: What is well-supported? What is fragile? What would you do next?

* **Pseudoscience / Weak Science Clinic**

  * Choose a controversial or dubious claim (e.g., a fad intervention, pop-neuroscience bestseller).
  * Use the course’s tools to dissect methods, reasoning, and institutional context.
  * Produce a public-facing explanation (blog-style or short video script) translating your critique.

3. **Bridge Back to the Whole Curriculum**

* Connect explicitly:

  * **Data Literacy** → how measurements become evidence.
  * **Causality** → how we argue that X really affects Y.
  * **Heuristics & Bias** → how humans systematically mis-handle evidence and uncertainty.
  * **Analytical Thinking** → problem framing, decomposition, and argument evaluation.
  * **Systems Thinking** → institutions and research ecosystems as dynamic systems.
  * **Model Thinking** → models as explicit, testable scientific stories.

* Final meta-message:

  > Scientific reasoning is *structured, collective, and self-correcting* – but only when we design methods, models, and institutions to earn that reputation. Your job as a critical thinker is to *see and evaluate* that structure rather than either worship or dismiss “science” as a black box.

---

[1]: https://plato.stanford.edu/entries/pseudo-science/ "Science and Pseudo-Science"
[2]: https://en.wikipedia.org/wiki/Abductive_reasoning "Abductive reasoning"
[3]: https://plato.stanford.edu/entries/science-theory-observation/ "Theory and Observation in Science"
[4]: https://plato.stanford.edu/entries/scientific-method/ "Scientific Method - Stanford Encyclopedia of Philosophy"
[5]: https://www.cambridge.org/core/books/theoretical-virtues-in-science/BEECC887D80F03C8FFAC1EDBA0D30B05 "Theoretical Virtues in Science"
[6]: https://plato.stanford.edu/entries/scientific-explanation/ "Scientific Explanation - Stanford Encyclopedia of Philosophy"
[7]: https://en.wikipedia.org/wiki/Publication_bias "Publication bias"
[8]: https://en.wikipedia.org/wiki/Reproducibility "Reproducibility"
[9]: https://en.wikipedia.org/wiki/Metascience "Metascience"
[10]: https://en.wikipedia.org/wiki/The_Grammar_of_Science "The Grammar of Science"
[11]: https://plato.stanford.edu/entries/scientific-objectivity/ "Scientific Objectivity - Stanford Encyclopedia of Philosophy"
[12]: https://en.wikipedia.org/wiki/Design_of_experiments "Design of experiments"
[13]: https://www.gutenberg.org/files/37157/37157-pdf.pdf "Science and Hypothesis."
[14]: https://link.springer.com/book/10.1007/978-1-4419-8562-0 "Abduction, Reason and Science - Book"
[15]: https://philpapers.org/rec/WALAR-6 "Abductive Reasoning - Douglas Walton"
[16]: https://direct.mit.edu/books/monograph/4723/Theory-and-EvidenceThe-Development-of-Scientific "Theory and Evidence: The Development of Scientific ..."
[17]: https://www2.psych.ubc.ca/~schaller/528Readings/BullockGreenHa2010.pdf "Yes, But What's the Mechanism? (Don't Expect an Easy ..."
[18]: https://en.wikipedia.org/wiki/Category%3ABranches_of_science "Category:Branches of science"
[19]: https://en.wikipedia.org/wiki/Science_and_Hypothesis "Science and Hypothesis"
[20]: https://digitalcommons.usf.edu/oa_textbooks/3/ "Social Science Research: Principles, Methods, and Practices"
[21]: https://en.wikipedia.org/wiki/Scientific_modelling "Scientific modelling"
[22]: https://pubmed.ncbi.nlm.nih.gov/30896212/ "Constructing validity: New developments in creating ... - PubMed"
[23]: https://www.amazon.com/Abduction-Reason-Science-Processes-Explanation/dp/0306465140 "Abduction, Reason and Science: Processes of Discovery ..."
[24]: https://journals.asm.org/doi/10.1128/mbio.01902-16 "Rigorous Science: a How-To Guide | mBio - ASM Journals"
[25]: https://www.sciencedirect.com/science/article/pii/S0022103113001819 "The Replication Recipe: What makes for a convincing ..."
[26]: https://en.wikipedia.org/wiki/Category%3AScientific_method "Category:Scientific method"
