# Course overview: Media Studies, Propaganda & Critical Thinking (with Computational + Participatory Disinformation)

---

## Big question

How do modern media ecosystems shape what people *notice*, *believe*, and *do*—and how can we build the skills and virtues needed to resist manipulation while still learning appropriately from testimony and expertise?

## By the end, students should be able to

* Map an information ecosystem (platforms, incentives, institutions, audiences) and explain how it shapes belief formation (attention, algorithms, business models). ([Media Manipulation & Disinformation—Data & Society][3])
* Distinguish **misinformation, disinformation, propaganda, persuasion, spin, PR, and psychological manipulation** (and explain why the boundaries matter). ([Media Manipulation Casebook—Definitions][6]) ([NATO on “information threats” terminology][26])
* Identify recurring propaganda patterns (e.g., **big lie**, **moral panic**, **DARVO**, **gaslighting**, **scapegoating**, **black propaganda**, **astroturfing**), and analyze how they work. ([Propaganda Survival Guide—MIT OCW][12])
* Explain *political communication* mechanisms (agenda-setting, framing, priming) and connect them to platforms and polarization. ([McCombs & Shaw agenda-setting PDF][33]) ([Entman Framing PDF][35]) ([Iyengar & Kinder excerpt PDF][34])
* Explain and recognize **computational propaganda** (automation + targeting + algorithmic amplification + cross-platform laundering). ([OII ComProp report page][29]) ([DemTech “What is ComProp?”][30])
* Explain and analyze **participatory disinformation** (audiences as co-producers; disinformation as collaborative work; media “improv theater” dynamics). ([Starbird “Disinformation as Collaborative Work” PDF][37]) ([Starbird/DiResta/DeButts participatory disinfo][39]) ([CIP “improv theater” piece][40])
* Explain rumor-making in catastrophe situations as collective sensemaking under uncertainty, and how those dynamics can be exploited. ([Crisis Informatics PDF][41]) ([Starbird & Palen “Voluntweeters” PDF][42]) ([Mendoza et al. “Twitter Under Crisis” PDF][43])
* Explain how **dehumanization** functions as a propaganda payload and a permission structure for cruelty/exclusion. ([Smith *On Inhumanity*—OUP page][44]) ([Smith *Less Than Human*—publisher page][45])
* Analyze **reaction and resentment** as recurring engines of mass persuasion (grievance, betrayal scripts, anti-elitism, “common sense” epistemic style), and how these are stabilized by media ecosystems and participatory performance. (Unit 8 integrates with dehumanization + ideology and explicitly teaches “reaction/resentment” as reusable rhetorical forms.)
* Diagnose media arguments using informal logic/argumentation tools (framing, ambiguity, expert authority, bias, fear appeals, ad hominem, straw man). ([MIT OCW lecture notes set][13])
* Explain how conspiracy beliefs spread and stabilize (echo chambers, epistemic bunkers, evidential preemption, groupstrapping, hostile epistemology). ([HKS Misinformation Review][4])
* Evaluate testimony and expertise under uncertainty (expert authority checks, conflicts of interest, peer disagreement, higher-order evidence). ([SIFT method][1])
* Apply practical verification and “information triage” methods: **SIFT**, **lateral reading**, source tracing, triangulation, reverse-image basics, and “follow the claim to the primary.” ([SIFT method][1]) ([Civic Online Reasoning—lateral reading lessons][14])
* Design countermeasures: **debunking** and **prebunking** strategies that reduce amplification and avoid common failure modes (salience traps, attention hijacking). ([HKS Misinformation Review][4])
* Produce a principled stance toward media: neither gullible nor cynically “nothing is knowable,” but *calibrated, accountable, and context-sensitive*. ([RAND Truth Decay][8])

---

## Unit 1 – Media Ecosystems: Incentives, Institutions, and Attention

**Guiding questions**

* Why is “the media” best understood as an ecosystem (not just outlets)?
* How do incentives (attention, ad revenue, status, ideology, career) shape content?
* Why do some claims go viral even when they’re weak?

**Sub-units**

1. **From messages to systems**

   * Information problems vs incentive problems; why “more facts” often fails.
   * Media manipulation as coordinated practice, not just isolated falsehoods. ([Media Manipulation Casebook—About][5])
2. **Attention engineering**

   * Ranking, virality, outrage, and “engagement as selection pressure.”
   * Case method: trace a narrative’s spread across platforms. ([Media Manipulation Casebook—Case Studies][7])
3. **Institutions, legitimacy, and trust**

   * Journalistic norms and critiques; trust as a social resource.
   * “Truth Decay” as macro-pattern. ([RAND Truth Decay][8])

**Core resources**

* [Media Studies 101][2]
* [Data & Society: Media Manipulation & Disinformation][3]
* [HKS Misinformation Review][4]
* [Media Manipulation Casebook][5]

---

## Unit 2 – Political Communication Foundations: Agenda-Setting, Framing, Priming

**Guiding questions**

* How do media shape *what* people think about (agenda-setting) vs *how* they interpret it (framing)?
* How does salience become power?
* How do evaluative standards shift (priming)?

**Sub-units**

1. Agenda-setting: salience and issue attention ([McCombs & Shaw agenda-setting PDF][33])
2. Framing: selection + salience + causal stories ([Entman Framing PDF][35])
3. Priming: attention → criteria for evaluation ([Iyengar & Kinder excerpt PDF][34])
4. Bridging to today: platforms, influencers, and participatory agenda-setting

**Core resources**

* [McCombs & Shaw PDF][33]
* [Entman PDF][35]
* [Iyengar & Kinder excerpt PDF][34]

---

## Unit 3 – What Is Propaganda? Definitions, Types, and Ethical Boundaries

**Guiding questions**

* When does persuasion become propaganda?
* Can propaganda ever be “for good,” or is it inherently corruptive?
* Why are definitional fights themselves strategic?

**Sub-units**

1. **Conceptual distinctions**

   * Propaganda vs persuasion vs education vs PR vs disinformation.
   * Why taxonomy matters for accountability and regulation. ([Media Manipulation Casebook—Definitions][6]) ([NATO on “information threats” terminology][26])
2. **Classic frameworks**

   * Manufacturing-consent style models; PR as legitimacy-production.
3. **Black / gray / white propaganda**

   * Source concealment, identity laundering, plausible deniability.
4. **Ethical lenses**

   * Autonomy, manipulation, consent, dignity, democratic deliberation.

**Core resources**

* [Propaganda Survival Guide—MIT OCW][12]
* [MIT OCW CMS.701 lecture notes set][13]
* [EU DisinfoLab][9]
* [NATO StratCom COE—Disinformation publications][10]

---

## Unit 4 – Media Argumentation: How Mass Media “Makes the Case”

**Guiding questions**

* How do news and punditry argue without looking like argument?
* What are the most common media fallacies and distortions?
* How do quotation, clipping, and re-reporting change meaning?

**Sub-units**

1. **Media argumentation as a genre**

   * Narrative packaging; framing-as-inference guidance.
2. **Ambiguity and strategic vagueness**

   * Equivocation, motte-and-bailey drift, implicature-as-deniability.
3. **One-sidedness and bias as argument-structure**

   * Missing alternatives; selective standards of evidence; motivated skepticism.
4. **Threat politics**

   * Fear appeals, scapegoating, “folk devils,” moral panic amplification.

**Core resources**

* [MIT OCW lecture notes set][13]
* [Paul & Elder mini-guide PDF][11]
* [Media Manipulation Casebook—Definitions][6]

---

## Unit 5 – Computational Propaganda & Platform Manipulation

**Guiding questions**

* What’s new about propaganda in the age of platforms?
* How do automation, microtargeting, and recommender systems change persuasion?
* How do researchers study coordination without overclaiming?

**Sub-units**

1. **What computational propaganda is**

   * Algorithms + automation + human curation as a persuasive assemblage. ([DemTech “What is ComProp?”][30]) ([OII ComProp report page][29])
2. **Infrastructure & tactics (conceptual literacy)**

   * Bots, sockpuppets, astroturfing; influencer pipelines; microtargeting; engagement manipulation.
3. **Algorithmic amplification**

   * Why some content gets selected; “engagement as selection pressure” revisited.
4. **Cross-platform laundering and content supply chains**

   * Seeding → laundering → amplification → mainstream pickup → feedback. ([Cross-platform disinformation PDF][38])
5. **Methods lab (defensive/analytic only)**

   * Signals of coordination: temporal bursts, co-sharing graphs, network roles, domain tracing (high-level).

**Core resources**

* [OII ComProp report page][29]
* [DemTech “What is ComProp?”][30]
* [Cross-platform disinformation (Wilson & Starbird) PDF][38]

---

## Unit 6 – Crisis Informatics & Rumor-Making in Catastrophe Situations

**Guiding questions**

* Why does rumor spike in crises?
* What does “collective sensemaking” look like online?
* What’s the difference between correction, contestation, and escalation?

**Sub-units**

1. **Crisis informatics: disasters as information shocks** ([Crisis Informatics PDF][41])
2. **Digital volunteerism and emergent coordination** ([Voluntweeters PDF][42])
3. **Rumor diffusion and correction dynamics** ([Twitter Under Crisis PDF][43])
4. **Exploitation of crisis sensemaking**

   * When political/ideological entrepreneurs harness uncertainty; bridge to computational propaganda.
5. **Verification lab**

   * SIFT + lateral reading + basic source tracing under time pressure.

**Core resources**

* [Crisis Informatics PDF][41]
* [Starbird & Palen “Voluntweeters” PDF][42]
* [Mendoza et al. “Twitter Under Crisis” PDF][43]
* [SIFT method][1] + [Lateral reading collection][14]

---

## Unit 7 – Participatory Disinformation: Disinformation as Collaborative Work

**Guiding questions**

* Why does disinformation often look like *community activity* rather than top-down manipulation?
* How do “deep stories” and shared roles recruit participants?
* What changes when audiences become co-producers?

**Sub-units**

1. **Disinformation as collaborative work**

   * Participation as the engine; strategic ops as “work within crowds.” ([Starbird collaborative work PDF][37])
2. **Participatory disinformation in elections**

   * Influencers + hyperpartisan media + ordinary people co-producing claims. ([Participatory disinformation paper][39])
3. **Cross-platform campaigns**

   * Different platforms doing different jobs in the same campaign. ([Cross-platform disinformation PDF][38])
4. **Media as performance (“improv theater”)**

   * Role-taking, prompts, feedback loops, and narrative maintenance. ([CIP improv theater][40])
5. **Methods: mixed-method analysis**

   * Interpretive + network + narrative tracing; evidence standards and humility.

**Core resources**

* [Starbird “Disinformation as Collaborative Work” PDF][37]
* [Starbird/DiResta/DeButts participatory disinfo][39]
* [Cross-platform disinformation PDF][38]
* [CIP “improv theater” piece][40]

---

## Unit 8 – Reaction, Resentment, and Dehumanization: The Moral Psychology of Propaganda

**Guiding questions**

* What is *reaction* as a recurring political style, and why is it rhetorically reusable?
* How does *resentment* (grievance, betrayal, humiliation, status threat) power persuasion?
* Why is dehumanization such an effective propaganda payload—and how does it pair with reaction/resentment?

**Sub-units**

1. **Reaction as a toolkit of argument forms**

   * Reusable patterns: betrayal scripts, “common sense” epistemology, anti-elitism, moralized skepticism, “they’re coming for you,” “everything is rigged,” etc.
   * How these become stable across decades while swapping surface topics.
2. **Resentment as recruitment fuel**

   * Outrage and grievance as identity glue; purity and traitor narratives; “enemy within” dynamics.
   * Connect back to Unit 10 (outrage) and Unit 7 (participation/performance).
3. **Dehumanization as permission structure (David Livingstone Smith)**

   * Not just insults: a cognitive-moral shift that changes what feels permissible. ([Smith *On Inhumanity*][44]) ([Smith *Less Than Human*][45])
4. **How reaction/resentment + dehumanization become participatory**

   * Shared villains; role assignment; “doing your part” by posting “evidence” and policing dissent.

5. **Anti-intellectualism and epistemic style**

   * Suspicion of expertise; romance of “common sense”; performative skepticism.

6. **Devotion and invulnerable ideals**

   * Why some beliefs become sacred, insulated, non-negotiable.

7. **Close-reading lab**

   * Identify: frame → implied treatment → emotional lever → audience function → incentives for repetition.

**Core resources**

* [Smith *On Inhumanity*—OUP][44]
* [Smith *Less Than Human*—publisher][45]
* [MIT Propaganda Survival Guide][12] (paired sections on stereotypes/agency and propaganda techniques)
* [Media Manipulation Casebook—Case Studies][7] (for applied coding)

---

## Unit 9 – Authority, Expertise, and the Fragmentation of Intellectual Autonomy

**Guiding questions**

* When is it rational to defer to experts?
* How do fake experts and “credential theater” work?
* What happens when expertise becomes polarized?

**Sub-units**

1. **Expertise as a social technology**

   * Deference, division of epistemic labor, and “outsourcing judgment” under overload.

2. **Conflicts of interest and reputation management**

   * Think tanks, PR pipelines, sponsored research, “policy-based evidence.”

3. **Higher-order evidence & peer disagreement**

   * How to update when smart people disagree; what counts as legitimate dissent.

4. **Practical expert-check workflow (lab)**

   * Identify domain; check consensus signals; audit conflicts; triangulate coverage; trace to primary.

**Core resources**

* [SIFT method][1]
* [First Draft—Training archive][15]
* [Bellingcat—Toolkit / guides hub][17] + [Beginner verification guide][18]
* [DFRLab—About][19] + [Training][20]

---

## Unit 10 – Moral Panics, Outrage, and the Social Psychology of Attention

**Guiding questions**

* How do “folk devils” get manufactured?
* Why does outrage feel like insight?
* How do media cycles convert uncertainty into certainty?

**Sub-units**

1. The panic machine: trigger events → amplification → entrepreneurs → backlash
2. Outrage as attention currency: incentives for escalation; status games; purity spirals
3. Risk perception and salience: vividness beats base rates; repetition effects
4. Designing “de-outrage” habits: slowing down, triangulation, structured doubt without cynicism

**Core resources**

* [4D Model—Michigan Online Teach-Out][22]
* [HKS Misinformation Review][4]

---

## Unit 11 – Conspiracy Theories: Suspicion, Insulation, and the Paranoid Style

**Guiding questions**

* What distinguishes healthy suspicion from conspiracism?
* Why do conspiracy beliefs persist despite counterevidence?
* How do conspiracies function as propaganda for deeper beliefs?

**Sub-units**

1. Definitions and boundary cases: real conspiracies vs conspiracism
2. Evidential insulation: preemption, self-sealing explanations, motivated standards
3. Social scaffolding: epistemic bunkers, groupstrapping, hostile epistemology
4. Conspiracy as identity narrative: meaning-making, devotion, resentment

**Core resources**

* [RAND Truth Decay][8]
* [ISD—Disinformation hub][24]
* [EU DisinfoLab][9]

---

## Unit 12 – Influence Infrastructure: PR, Think Tanks, Lobbying, and Manufactured Legitimacy

**Guiding questions**

* How do institutions shape belief without straightforward lying?
* What is astroturfing, and how does it differ from grassroots action?
* How do money, networks, and legitimacy-production interact?

**Sub-units**

1. PR, reputation management, agenda setting
2. Think tanks and policy laundering: op-ed pipelines, expert placement
3. Campaign/tooling literacy: evidence standards for coordination and attribution
4. Dossier lab: actors, funding, intermediaries, message evolution, distribution channels

**Core resources**

* [NATO StratCom COE—Disinformation publications][10]
* [GDI (Global Disinformation Index)][25]
* [DFRLab—Research][21]

---

## Unit 13 – Countermeasures: Debunking, Prebunking, and “Talking Back” Without Feeding the Fire

**Guiding questions**

* What makes debunking effective—and what makes it backfire?
* How do you respond without amplifying manipulation?
* How do we build mental immunity without paranoia?

**Sub-units**

1. **The epistemology of debunking**

   * What counts as success: truth, justification, resilience, behavior change?

2. **Debunking failure modes**

   * “Salience traps,” attention hijacking, identity threat, defensive processing.

3. **Prebunking / inoculation**

   * Teaching tactics and pattern-recognition rather than litigating every claim.

4. **Talking back**

   * Dialogue discipline; steelmanning; boundary-setting; knowing when not to engage.

**Core resources**

* [Civic Online Reasoning curriculum][16]
* [Teaching Lateral Reading collection][14]
* [HKS Misinformation Review][4]

---

## Unit 14 – Agency in a Manipulated World: Indoctrination, Surveillance, and Epistemic Self-Defense

**Guiding questions**

* What is indoctrination (vs persuasion vs education)?
* When does “transparency” become surveillance?
* How do we cultivate resilience without drifting into conspiracism?

**Sub-units**

1. **Indoctrination and autonomy**

   * Control of defeaters, social costs of doubt, identity capture.

2. **Cultic dynamics as a diagnostic lens**

   * Use carefully: as pattern-recognition, not as a labeling weapon.

3. **Transparency and surveillance**

   * Chilling effects; metric capture; coercive visibility.

4. **Playfulness vs. epistemic traps**

   * Rebuilding agency: curiosity, humor, reversible commitments, exit ramps.

**Core resources**

* [BITE Model PDF][23]
* [NATO approach to counter information threats][26]
* Optional meta-cases: [CrowdTangle shutdown context][27] + [Stanford Internet Observatory report][28]

---

# Skills labs running through the whole course (recommended)

* **SIFT + lateral reading** as default verification reflex. ([SIFT method][1]) ([Lateral reading collection][14])
* **Claim decomposition:** isolate claim → implied evidence → observation vs interpretation → plausible alternatives
* **Source & incentive audit:** who benefits, who pays, who risks?
* **Argument reconstruction:** headline/clip → premises/conclusion; test ambiguity, bias, missing defeaters
* **Narrative tracing:** map how narratives move (influencer → blog → mainstream) and where laundering occurs. ([Media Manipulation Casebook—Case Studies][7])
* **Coordination literacy (defensive):** signals of coordinated amplification vs organic spread (Unit 5/7 integration)
* **Close-reading for reaction/resentment + dehumanization payloads:** frame → emotion → implied treatment → audience function (Unit 8 integration)
* **Response practice:** write (a) correction, (b) boundary-setting reply, (c) de-escalating move, (d) “don’t amplify” strategy

---

# Possible capstone activities (updated)

1. **Propaganda + participation dossier (ecosystem case study)**
   Dossier: timeline, actors, incentives, platform roles, argument patterns, reaction/resentment hooks, dehumanization frames (if present), participatory dynamics, and countermeasure plan. Use Casebook vocabulary. ([Media Manipulation Casebook—Definitions][6])

2. **Crisis rumor ecology analysis**
   Track a crisis rumor: uncertainty cues, volunteer coordination, correction dynamics, opportunistic exploitation, cross-platform jumps. Tie to crisis-informatics readings. ([Crisis Informatics PDF][41])

3. **Participatory disinformation “improv” analysis**
   Map roles (heroes/villains/traitors), prompts, influencer improvisation, audience co-production, and how resentment scripts stabilize commitment. ([Starbird collaborative work PDF][37]) ([CIP improv theater][40])

4. **Build a resilience toolkit (audience-specific)**
   Practical guide: verification habits, prebunking patterns, “when not to engage,” ethical guardrails.

5. **Red-team / blue-team simulation (ethical, classroom-bounded)**
   Model likely tactics *without deploying them*, then design defenses: early detection, inoculation, norms, and platform-aware friction.

---

## References (original + additions)

[1]: https://guides.lib.uchicago.edu/c.php?g=1241077&p=9082322& "The SIFT Method - Evaluating Resources and Misinformation"
[2]: https://opentextbc.ca/mediastudies101/? "Media Studies 101"
[3]: https://datasociety.net/research/media-manipulation/? "Media Manipulation & Disinformation (Data & Society)"
[4]: https://misinforeview.hks.harvard.edu/? "HKS Misinformation Review"
[5]: https://mediamanipulation.org/? "Media Manipulation Casebook: Homepage"
[6]: https://mediamanipulation.org/definitions/? "Definitions"
[7]: https://mediamanipulation.org/case-studies/? "Case Studies"
[8]: https://www.rand.org/research/projects/truth-decay.html? "Countering Truth Decay"
[9]: https://www.disinfo.eu/? "EU DisinfoLab"
[10]: https://stratcomcoe.org/publications?tid%5B%5D=30& "NATO StratCom COE: Disinformation publications"
[11]: https://www.criticalthinking.org/TGS_files/SAM-MediaBias.pdf? "How to Detect Media Bias & Propaganda"
[12]: https://ocw.mit.edu/courses/cms-701-current-debates-in-media-spring-2015/resources/mitcms_701s15_srvivalguid/? "CMS.701 Propaganda Survival Guide"
[13]: https://ocw.mit.edu/courses/cms-701-current-debates-in-media-spring-2015/pages/lecture-notes/? "MIT OCW CMS.701 lecture notes"
[14]: https://cor.inquirygroup.org/curriculum/collections/teaching-lateral-reading/? "Teaching Lateral Reading - Civic Online Reasoning"
[15]: https://firstdraftnews.org/bucket/our-training/? "First Draft training archive"
[16]: https://cor.inquirygroup.org/? "Civic Online Reasoning - Digital Inquiry Group"
[17]: https://bellingcat.gitbook.io/toolkit/resources/guides-and-handbooks? "Bellingcat Toolkit hub"
[18]: https://www.bellingcat.com/resources/2021/11/01/a-beginners-guide-to-social-media-verification/? "Bellingcat verification guide"
[19]: https://dfrlab.org/about/? "DFRLab - About"
[20]: https://dfrlab.org/training/? "DFRLab - Training + Resources"
[21]: https://dfrlab.org/research/? "DFRLab - Research and Analysis"
[22]: https://online.umich.edu/teach-outs/disinformation-misinformation-and-fake-news-teach-out/lessons/4d-model-disinformation-campaigns/? "4D Model (Michigan Online Teach-Out)"
[23]: https://freedomofmind.com/wp-content/uploads/2023/08/BITE-model.pdf? "BITE Model PDF"
[24]: https://www.isdglobal.org/disinformation/? "ISD disinformation hub"
[25]: https://www.disinformationindex.org/? "Global Disinformation Index"
[26]: https://www.nato.int/en/what-we-do/wider-activities/natos-approach-to-counter-information-threats? "NATO approach to counter information threats"
[27]: https://www.wired.com/story/meta-kills-crucial-transparency-tool-worst-possible-time? "CrowdTangle shutdown context"
[28]: https://www.platformer.news/stanford-internet-observatory-shutdown-stamos-diresta-sio/? "Stanford Internet Observatory dismantling report"
[29]: https://www.oii.ox.ac.uk/research/publications/computational-propaganda-political-parties-politicians-and-political-manipulation-on-social-media-2/? "OII: Computational Propaganda (report/book page)"
[30]: https://navigator.oii.ox.ac.uk/what-is-comprop/? "DemTech Navigator: What is Computational Propaganda?"
[33]: https://fbaum.unc.edu/teaching/articles/POQ-1972-McCOMBS-176-87.pdf? "McCombs & Shaw (1972) Agenda-setting (PDF)"
[34]: https://www.uvm.edu/~dguber/POLS293/articles/iyengar.pdf? "Iyengar & Kinder (News That Matters) excerpt (PDF)"
[35]: https://fbaum.unc.edu/teaching/articles/J-Communication-1993-Entman.pdf? "Entman (1993) Framing (PDF)"
[37]: https://faculty.washington.edu/kstarbi/Disinformation-as-Collaborative-Work-Authors-Version.pdf? "Starbird et al. (2019) Disinformation as Collaborative Work (PDF)"
[38]: https://misinforeview.hks.harvard.edu/wp-content/uploads/2020/01/V2_starbird_crossplatform_jan29.pdf? "Wilson & Starbird (2020) Cross-Platform Disinformation Campaigns (PDF)"
[39]: https://journals.sagepub.com/doi/10.1177/20563051231177943? "Starbird, DiResta & DeButts (2023) Participatory Disinformation during the 2020 US Election"
[40]: https://www.cip.uw.edu/2024/12/04/right-wing-media-improv-theater/? "CIP: Right-wing media as improv theater (Tomson & Starbird)"
[41]: https://cmci.colorado.edu/~palen/palen_papers/palen-crisisinformatics.pdf? "Palen et al. (2007) Crisis Informatics (PDF)"
[42]: https://cmci.colorado.edu/~palen/voluntweetersStarbirdPalen.pdf? "Starbird & Palen (2011) Voluntweeters (PDF)"
[43]: https://snap.stanford.edu/soma2010/papers/soma2010_11.pdf? "Mendoza et al. (2010) Twitter Under Crisis (PDF)"
[44]: https://global.oup.com/academic/product/on-inhumanity-9780190923006? "David Livingstone Smith: On Inhumanity (OUP page)"
[45]: https://us.macmillan.com/books/9781250003836/lessthanhuman/? "David Livingstone Smith: Less Than Human (publisher page)"