# Course overview: Media Studies & Propaganda

---

**Big question:**
How do modern media ecosystems shape what people *notice*, *believe*, and *do*—and how can we build the skills and virtues needed to resist manipulation while still learning from testimony and expertise?

**By the end, students should be able to:**

* Map an information ecosystem (platforms, incentives, institutions, audiences) and explain how it shapes belief formation (attention, algorithms, business models). ([Media Manipulation & Disinformation—Data & Society][3])
* Distinguish **misinformation, disinformation, propaganda, persuasion, spin, PR, and psychological manipulation** (and explain why the boundaries matter). ([Media Manipulation Casebook—Definitions][6]) ([NATO on “information threats” terminology][26])
* Identify recurring propaganda patterns (e.g., **big lie**, **moral panic**, **DARVO**, **gaslighting**, **scapegoating**, **black propaganda**, **astroturfing**) and analyze how they work. ([Propaganda Survival Guide—MIT OCW][12])
* Diagnose **media arguments** using tools from informal logic and argumentation theory (framing, ambiguity, expert authority, bias, fear appeals, ad hominem, straw man). ([MIT OCW lecture notes set][13])
* Explain how conspiracy beliefs spread and stabilize (echo chambers, epistemic bunkers, evidential preemption, groupstrapping, hostile epistemology). ([HKS Misinformation Review][4])
* Evaluate testimony and expertise under uncertainty (expert authority checks, conflicts of interest, peer disagreement, higher-order evidence). ([SIFT method][1])
* Apply practical verification and “information triage” methods: **SIFT**, **lateral reading**, source tracing, triangulation, reverse-image basics, and “follow the claim to the primary.” ([SIFT method][1]) ([Civic Online Reasoning—lateral reading lessons][14])
* Design countermeasures: **debunking** and **prebunking** strategies that reduce amplification and avoid common failure modes (salience traps, attention hijacking). ([HKS Misinformation Review][4])
* Produce a principled stance toward media: neither gullible nor cynically “nothing is knowable,” but *calibrated, accountable, and context-sensitive*. ([RAND Truth Decay][8])

---

## Unit 1 – Media Ecosystems: Incentives, Institutions, and Attention

**Guiding questions**

* Why is “the media” best understood as an ecosystem (not just outlets)?
* How do incentives (attention, ad revenue, status, ideology, career) shape content?
* Why do some claims go viral even when they’re weak?

**Sub-units**

1. **From messages to systems**

   * Information problems vs. incentive problems; why “more facts” often fails.
   * Media manipulation as coordinated practice, not just isolated falsehoods. ([Media Manipulation Casebook—About][5])

2. **Attention engineering**

   * Ranking, virality, outrage, and “engagement as selection pressure.”
   * Case method: trace a narrative’s spread across platforms. ([Media Manipulation Casebook—Case Studies][7])

3. **Institutions, legitimacy, and trust**

   * Journalistic objectivity norms, criticism of journalism, and institutional trust.
   * “Truth Decay” as a macro-pattern: diminished role of facts and analysis in public life. ([RAND Truth Decay][8])

**Core readings / resources**

* **Media Studies 101** (open textbook; use as a backbone for media theory basics). ([Media Studies 101][2])
* **Data & Society: Media Manipulation & Disinformation** (research hub + reports). ([Media Manipulation & Disinformation—Data & Society][3])
* **HKS Misinformation Review** (short, accessible peer-reviewed research articles/notes/commentary). ([HKS Misinformation Review][4])
* **Media Manipulation Casebook** (theory + methods + coded cases). ([Media Manipulation Casebook—About][5])

---

## Unit 2 – What Is Propaganda? Definitions, Types, and Ethical Boundaries

**Guiding questions**

* When does persuasion become propaganda?
* Can propaganda ever be “for good,” or is it inherently corruptive?
* Why are definitional fights themselves strategic?

**Sub-units**

1owd:

1. **Conceptual distinctions**

   * Propaganda vs. persuasion vs. education vs. PR vs. disinformation.
   * Why taxonomy matters for accountability and regulation. ([Media Manipulation Casebook—Definitions][6])

2. **Classic frameworks**

   * Manufacturing-consent style models, agenda setting, and “public relations as legitimacy-production.” (Pair with curated Chomsky/Bernays video track.)

3. **Black / gray / white propaganda**

   * Source concealment, identity laundering, plausible deniability.

4. **Ethical lenses**

   * Autonomy, manipulation, consent, dignity, democratic deliberation.

**Core readings / resources**

* **MIT OCW “Propaganda Survival Guide”** (excellent compact primer + reading spine). ([Propaganda Survival Guide—MIT OCW][12])
* **MIT OCW CMS.701 lecture notes list** (propaganda/censorship + adjacent themes). ([MIT OCW lecture notes set][13])
* **EU DisinfoLab** (Europe-focused disinformation investigations + community). ([EU DisinfoLab][9])
* **NATO StratCom COE publications (disinformation tag)** (resilience, tactics, campaign patterns). ([NATO StratCom COE—Disinformation publications][10])

---

## Unit 3 – Media Argumentation: How Mass Media “Makes the Case”

**Guiding questions**

* How do news and punditry argue without looking like argument?
* What are the most common media fallacies and distortions?
* How do quotation, clipping, and re-reporting change meaning?

**Sub-units**

1. **Media argumentation as a genre**

   * Narrative packaging, rhetorical priming, framing-as-inference guidance.

2. **Ambiguity and strategic vagueness**

   * Equivocation, motte-and-bailey drift, “plausible deniability” via implicature.

3. **One-sidedness and bias as argument-structure**

   * Missing alternatives, selective standards of evidence, motivated skepticism.

4. **Threat politics**

   * Fear appeals, scapegoating, “folk devils,” moral panic amplification.

**Core readings / resources (additions)**

* **MIT OCW CMS.701: “Ideologies and Conceptual Maps,” “Stereotypes and Agency,” “Propaganda and Censorship”** (use as applied lecture modules). ([MIT OCW lecture notes set][13])
* **Paul & Elder: How to Detect Media Bias & Propaganda (mini-guide PDF)** (quick classroom tool). ([Paul & Elder mini-guide PDF][11])
* **Media Manipulation Casebook—Definitions** (use as a controlled vocabulary for analysis assignments). ([Media Manipulation Casebook—Definitions][6])

---

## Unit 4 – Authority, Expertise, and the Fragmentation of Intellectual Autonomy

**Guiding questions**

* When is it rational to defer to experts?
* How do fake experts and “credential theater” work?
* What happens when expertise becomes polarized?

**Sub-units**

1. **Expertise as a social technology**

   * Deference, division of epistemic labor, and “outsourcing judgment” under overload.

2. **Conflicts of interest and reputation management**

   * Think tanks, PR pipelines, sponsored research, “policy-based evidence.”

3. **Higher-order evidence & peer disagreement**

   * How to update when smart people disagree; what counts as legitimate dissent.

4. **Practical expert-check workflow (lab)**

   * Identify domain; check consensus signals; audit conflicts; triangulate coverage; trace to primary.

**Core readings / resources (additions)**

* **SIFT method** as the default *skill routine* for evaluating unfamiliar sources. ([SIFT method][1])
* **First Draft training archive** (practical verification, coordination, bots/inauthentic behavior—great lab prompts). ([First Draft—Training archive][15])
* **Bellingcat** (verification + OSINT habits; use beginner verification guide + toolkit hub). ([Bellingcat—Beginner’s verification guide][18]) ([Bellingcat—Toolkit / guides hub][17])
* **DFRLab training/research** (investigation methods + case-driven reports). ([DFRLab—About][19]) ([DFRLab—Training][20])

---

## Unit 5 – Moral Panics, Outrage, and the Social Psychology of Attention

**Guiding questions**

* How do “folk devils” get manufactured?
* Why does outrage feel like insight?
* How do media cycles convert uncertainty into certainty?

**Sub-units**

1. **The panic machine**

   * Trigger events → amplification → entrepreneurs → policy backlash.

2. **Outrage as an attention currency**

   * Incentives for escalation, purity spirals, status games.

3. **Risk perception and salience**

   * Why vividness beats base rates; how repeated exposure shapes belief.

4. **Designing “de-outrage” habits**

   * Slowing down, triangulation, and structured doubt without cynicism.

**Core readings / resources (additions)**

* **Michigan Online Teach-Out: 4D Model of disinformation campaigns** (dismiss/distort/distract/dismay—great for moral panic classification). ([4D Model—Michigan Online Teach-Out][22])
* **HKS Misinformation Review** (pick 2–3 pieces on interventions/polarization/outcomes per cohort). ([HKS Misinformation Review][4])

---

## Unit 6 – Conspiracy Theories: Suspicion, Insulation, and the Paranoid Style

**Guiding questions**

* What distinguishes healthy suspicion from conspiracism?
* Why do conspiracy beliefs persist despite counterevidence?
* How do conspiracies function as propaganda for deeper beliefs?

**Sub-units**

1. **Definitions and boundary cases**

   * “Conspiracy theory” vs. real conspiracies; bad uses of the label.

2. **Evidential insulation**

   * Preemption, self-sealing explanations, motivated standards of evidence.

3. **Social scaffolding**

   * Echo chambers, epistemic bunkers, groupstrapping.

4. **Conspiracy as identity narrative**

   * Meaning-making, devotion, resentment, invulnerable ideals.

**Core readings / resources (additions)**

* **RAND Truth Decay** (macro context: trust erosion and susceptibility). ([RAND Truth Decay][8])
* **ISD (Institute for Strategic Dialogue) disinformation research hub** (campaign patterns + election disinfo + case studies). ([ISD—Disinformation hub][24])
* **EU DisinfoLab** (e.g., “Doppelganger” and other campaigns—use as case dossier inputs). ([EU DisinfoLab][9])

---

## Unit 7 – Reaction, Resentment, and Mass Persuasion in Public Life

**Guiding questions**

* What rhetorical patterns keep “reaction” stable across decades?
* How do movements recruit through grievance and identity?
* How do propaganda and ideology interact?

**Sub-units**

1. **Reactionary rhetoric as reusable argument forms**

   * Perversity, futility, jeopardy patterns (and how to spot them in media talk).

2. **Anti-intellectualism and epistemic style**

   * Suspicion of expertise; romance of “common sense”; performative skepticism.

3. **Devotion and invulnerable ideals**

   * Why some beliefs become sacred, insulated, non-negotiable.

4. **Narratives of resentment**

   * Betrayal scripts, scapegoats, purity, and moralized epistemology.

**Core readings / resources (additions)**

* Use **MIT “Propaganda Survival Guide”** sections +  curated Hofstadter/Hirschman/Katsafanas readings as the unit spine. ([Propaganda Survival Guide—MIT OCW][12])

---

## Unit 8 – Influence Infrastructure: PR, Think Tanks, Lobbying, and Manufactured Legitimacy

**Guiding questions**

* How do institutions shape belief without straightforward lying?
* What is astroturfing, and how does it differ from grassroots action?
* How do money, networks, and legitimacy-production interact?

**Sub-units**

1. **PR, reputation management, agenda setting**

   * “Soft power” via credibility engineering.

2. **Think tanks and policy laundering**

   * Expert placement, op-ed pipelines, selective evidence standards.

3. **Campaign/tooling literacy**

   * How investigations trace coordination and attribution (carefully, without overclaiming).

4. **Dossier lab**

   * Students build an influence map: actors, funding, intermediaries, message evolution, distribution channels.

**Core readings / resources (additions)**

* **NATO StratCom COE disinformation publications** (campaign tooling + resilience). ([NATO StratCom COE—Disinformation publications][10])
* **GDI (Global Disinformation Index)** (risk, incentives, and disinfo business models—use selectively, alongside critique). ([GDI—What we do][25])
* **DFRLab research** (investigations as exemplars). ([DFRLab—Research][21])

---

## Unit 9 – Countermeasures: Debunking, Prebunking, and “Talking Back” Without Feeding the Fire

**Guiding questions**

* What makes debunking effective—and what makes it backfire?
* How do you respond without amplifying the manipulation?
* How do we build “mental immunity” without paranoia?

**Sub-units**

1. **The epistemology of debunking**

   * What counts as success: truth, justification, resilience, behavior change?

2. **Debunking failure modes**

   * “Salience traps,” attention hijacking, identity threat, defensive processing.

3. **Prebunking / inoculation**

   * Teaching tactics and pattern-recognition rather than litigating every claim.

4. **Talking back**

   * Dialogue discipline; steelmanning; boundary-setting; knowing when not to engage.

**Core readings / resources (additions)**

* **Civic Online Reasoning curriculum** (classroom-ready lessons + assessments). ([Civic Online Reasoning—site][16])
* **Intro to lateral reading + collection** (use as weekly labs). ([Civic Online Reasoning—lateral reading collection][14])
* **HKS Misinformation Review** (interventions and deterrence mechanisms; pick 2–3 per term). ([HKS Misinformation Review][4])

---

## Unit 10 – Agency in a Manipulated World: Indoctrination, Surveillance, and Epistemic Self-Defense

**Guiding questions**

* What is indoctrination (vs. persuasion vs. education)?
* When does “transparency” become surveillance?
* How do we cultivate resilience without drifting into conspiracism?

**Sub-units**

1. **Indoctrination and autonomy**

   * Control of defeaters, social costs of doubt, identity capture.

2. **Cultic dynamics as a diagnostic lens**

   * Use carefully: as pattern-recognition, not as a labeling weapon.

3. **Transparency and surveillance**

   * Chilling effects; metric capture; coercive visibility.

4. **Playfulness vs. epistemic traps**

   * Rebuilding agency: curiosity, humor, reversible commitments, exit ramps.

**Core readings / resources (additions)**

* **BITE Model of Authoritarian Control (PDF)** (as a structured checklist, cautiously applied). ([BITE model PDF][23])
* **NATO “approach to counter information threats”** (definitions, scope boundaries). ([NATO on “information threats” terminology][26])
* (Optional meta-case) Research transparency constraints as part of the environment (e.g., loss of monitoring tools / research centers). ([CrowdTangle shutdown context][27]) ([Stanford Internet Observatory dismantling report][28])

---

## Skills labs running through the whole course (recommended)

* **SIFT + lateral reading** as default verification reflex. ([SIFT method][1]) ([Civic Online Reasoning—Intro to lateral reading][14])
* **Claim decomposition**: isolate claim → identify implied evidence → separate observation from interpretation → list plausible alternatives.
* **Source & incentive audit**: who benefits, who pays, who risks?
* **Argument reconstruction**: turn a clip/headline into premises/conclusion; test for ambiguity, bias, missing defeaters.
* **Narrative tracing**: map how a narrative moves (influencer → blog → mainstream) and where “laundering” occurs. ([Media Manipulation Casebook—Case Studies][7])
* **Response practice**: write (a) a correction, (b) a boundary-setting reply, (c) a de-escalating dialogue move, (d) a “don’t amplify” strategy.

---

## Possible capstone activities

1. **Propaganda dossier (institutional case study)**
   Choose a live controversy and build a dossier: messaging timeline, actors, funding/incentives, platform strategy, argument patterns (fear appeals, expert theater, ambiguity, preemption). Use Casebook coding vocabulary. ([Media Manipulation Casebook—Definitions][6])

2. **Conspiracy ecology analysis**
   Track one conspiracy narrative and explain stabilizers: evidential insulation, groupstrapping, hostile epistemology, recruitment pathways (plus recommended interventions).

3. **Build a resilience toolkit**
   Design a practical guide for a target audience (students, parents, journalists): verification habits, debunking templates, “when not to engage,” and ethical guardrails.

4. **Red-team / blue-team simulation (ethical, classroom-bounded)**
   Teams model an influence campaign’s likely tactics *without deploying them*, then design defenses: early detection, inoculation messaging, community norms, and platform-aware distribution constraints.

---

[1]: https://guides.lib.uchicago.edu/c.php?g=1241077&p=9082322& "The SIFT Method - Evaluating Resources and Misinformation"
[2]: https://opentextbc.ca/mediastudies101/? "Media Studies 101"
[3]: https://datasociety.net/research/media-manipulation/? "Media Manipulation & Disinformation"
[4]: https://misinforeview.hks.harvard.edu/? "HKS Misinformation ReviewHKS Misinformation Review"
[5]: https://mediamanipulation.org/? "Media Manipulation Casebook: Homepage"
[6]: https://mediamanipulation.org/definitions/? "Definitions"
[7]: https://mediamanipulation.org/case-studies/? "Case Studies"
[8]: https://www.rand.org/research/projects/truth-decay.html? "Countering Truth Decay"
[9]: https://www.disinfo.eu/? "EU DisinfoLab"
[10]: https://stratcomcoe.org/publications?tid%5B%5D=30& "Disinformation"
[11]: https://www.criticalthinking.org/TGS_files/SAM-MediaBias.pdf? "How to Detect Media Bias & Propaganda"
[12]: https://ocw.mit.edu/courses/cms-701-current-debates-in-media-spring-2015/resources/mitcms_701s15_srvivalguid/? "CMS.701s15 Propaganda Survival Guide"
[13]: https://ocw.mit.edu/courses/cms-701-current-debates-in-media-spring-2015/pages/lecture-notes/? "Lecture Notes | Current Debates in Media"
[14]: https://cor.inquirygroup.org/curriculum/collections/teaching-lateral-reading/? "Teaching Lateral Reading - Civic Online Reasoning"
[15]: https://firstdraftnews.org/bucket/our-training/? "Our Training Archives - First Draft"
[16]: https://cor.inquirygroup.org/? "Civic Online Reasoning - Digital Inquiry Group"
[17]: https://bellingcat.gitbook.io/toolkit/resources/guides-and-handbooks? "Guides & Handbooks | Bellingcat's Online Investigation ..."
[18]: https://www.bellingcat.com/resources/2021/11/01/a-beginners-guide-to-social-media-verification/? "A Beginner's Guide to Social Media Verification"
[19]: https://dfrlab.org/about/? "About"
[20]: https://dfrlab.org/training/? "Training + Resources"
[21]: https://dfrlab.org/research/? "Research and Analysis"
[22]: https://online.umich.edu/teach-outs/disinformation-misinformation-and-fake-news-teach-out/lessons/4d-model-disinformation-campaigns/? "Disinformation, Misinformation, and Fake News Teach-Out"
[23]: https://freedomofmind.com/wp-content/uploads/2023/08/BITE-model.pdf? "BITE-model.pdf"
[24]: https://www.isdglobal.org/disinformation/? "Disinformation - ISD - We identify and analyse online ..."
[25]: https://www.disinformationindex.org/? "The Global Disinformation Index"
[26]: https://www.nato.int/en/what-we-do/wider-activities/natos-approach-to-counter-information-threats? "NATO's approach to counter information threats"
[27]: https://www.wired.com/story/meta-kills-crucial-transparency-tool-worst-possible-time? "Meta Kills a Crucial Transparency Tool At the Worst Possible Time"
[28]: https://www.platformer.news/stanford-internet-observatory-shutdown-stamos-diresta-sio/? "The Stanford Internet Observatory is being dismantled"
